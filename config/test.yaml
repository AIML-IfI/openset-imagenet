# General Parameters
log_name: testing.log  # name of the file with training info
gpu:                    # index of a GPU, if available
output_directory: experiments  # the directory where to write the model file

model_path: "{}/{}_{}_{}.pth" # for those which use pretrained model only

# Data Parameters
data:
  imagenet_path: /local/scratch/datasets/ImageNet/ILSVRC2012/ # ILSVRC2012 path
  #train_file: protocols/p{}_train.csv        # relative to data directory
  #val_file:   protocols/p{}_val.csv          # relative to data directory
  test_file:  protocols/p{}_test.csv         # relative to data directory

# Common parameters
batch_size: 64  # If distributed training the batch size is multiplied by the number of gpus
workers: 4      # Dataloader number of workers

optimized: # the parameter settings that provide optimal values on the val set
  evm:
    output_model_path: "{}/{}_{}_{}_{}.pkl" # directory/loss.type_alg.type_key_distance_metric.pth
    distance_metric: cosine
    cover_threshold: 1
    chunk_size: 100  # Why do we need this here? The model should be independent of the chunk size

    p1:
      softmax: {tailsize: 1000, distance_multiplier: 0.4}
      entropic: {tailsize: 1000, distance_multiplier: 0.2}
      garbage: {tailsize: 75, distance_multiplier: 0.7}

    p2:
      softmax: {tailsize: 300, distance_multiplier: 0.3}
      entropic: {tailsize: 150, distance_multiplier: 0.2}
      garbage: {tailsize: 1000, distance_multiplier: 0.2}

    p3:
      softmax: {tailsize: 100, distance_multiplier: 0.5}
      entropic: {tailsize: 1000, distance_multiplier: 0.2}
      garbage: {tailsize: 500, distance_multiplier: 0.5}


  openmax:
    output_model_path: "{}/{}_{}_{}_{}.pkl" # directory/loss.type_alg.type_key_distance_metric.pth
    distance_metric: cosine
    translateAmount: 1

    p1:
      softmax: {tailsize: 1000, distance_multiplier: 2.0, alpha: 10}
      entropic: {tailsize: 500, distance_multiplier: 2.0, alpha: 10}
      garbage: {tailsize: 1000, distance_multiplier: 1.5, alpha: 5}

    p2:
      softmax: {tailsize: 1000, distance_multiplier: 2.3, alpha: 10}
      entropic: {tailsize: 500, distance_multiplier: 2.0, alpha: 3}
      garbage: {tailsize: 750, distance_multiplier: 1.7, alpha: 5}

    p3:
      softmax: {tailsize: 750, distance_multiplier: 2.3, alpha: 5}
      entropic: {tailsize: 250, distance_multiplier: 2.0, alpha: 10}
      garbage: {tailsize: 1000, distance_multiplier: 2.3, alpha: 2}


  proser:
    output_model_path: "{}/{}_{}_{}_{}_{}.pth" # directory/loss.type_alg.type_epoch_dummycount_curr.pth

    p1:
      softmax: {epochs: 20, dummy_count: 1}
      entropic: {epochs: 20, dummy_count: 1}
      garbage: {epochs: 20, dummy_count: 1}

    p2:
      softmax: {epochs: 20, dummy_count: 1}
      entropic: {epochs: 20, dummy_count: 1}
      garbage: {epochs: 20, dummy_count: 1}

    # To be corrected
    p3:
      softmax: {epochs: 20, dummy_count: 1}
      entropic: {epochs: 20, dummy_count: 1}
      garbage: {epochs: 20, dummy_count: 1}
